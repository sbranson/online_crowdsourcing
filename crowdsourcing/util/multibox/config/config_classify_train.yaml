# Training specific configuration

RANDOM_SEED : 1.0

SESSION_CONFIG : {
  # If true, then the device location of each variable will be printed
  LOG_DEVICE_PLACEMENT : false,

  # How much GPU memory we are allowed to pre-allocate
  PER_PROCESS_GPU_MEMORY_FRACTION : 0.9
}

#################################################
# Dataset Info
#
# The number of classes we are classifying
NUM_CLASSES : 1001

# Number of training examples in the tfrecords. This is needed to compute the number of 
# batches in an epoch
NUM_TRAIN_EXAMPLES : 5994

# Maximum number of iterations to run before stopping
NUM_TRAIN_ITERATIONS : 20000

# The number of images to pass through the network in a single iteration
BATCH_SIZE : 32

# Which model architecture to use. 
MODEL_NAME : 'inception_v3'

# END: Dataset Info
#################################################
# Image Processing and Augmentation 
# There are 5 steps to image processing:
# 1) Extract regions from the image
# 2) Extract a crops from each region
# 3) Resize the crops for the network architecture
# 4) Flip the crops
# 5) Modify the colors of the crops
IMAGE_PROCESSING : {
    # All images will be resized to the [INPUT_SIZE, INPUT_SIZE, 3]
    INPUT_SIZE : 299,

    # 1) First we extract regions from the image
    # What type of region should be extracted, either 'image' or 'bbox'
    REGION_TYPE : 'image',

    # Specific whole image region extraction configuration
    WHOLE_IMAGE_CFG : {},

    # Specific bounding box region extraction configuration
    BBOX_CFG : {
        # We can centrally expand a bbox (i.e. turn a tight crop into a loose crop)
        # The fraction of time to expand the bounding box, 0 is never, 1 is always
        DO_EXPANSION : 1,
        EXPANSION_CFG : {
            WIDTH_EXPANSION_FACTOR : 2.0, # Expand the width by a factor of 2 (centrally)
            HEIGHT_EXPANSION_FACTOR : 2.0, # Expand the height by a factor of 2 (centrally)
        }
    },

    # 2) Then we take a random crop from the region
    # The fraction of time to take a random crop, 0 is never, 1 is always
    DO_RANDOM_CROP : 1,
    RANDOM_CROP_CFG : {
        MIN_AREA : 0.5, # between 0 and 1, how much of the region must be included
        MAX_AREA : 1.0, # between 0 and 1, how much of the region can be included
        MIN_ASPECT_RATIO : 0.7, # minimum aspect ratio of the crop
        MAX_ASPECT_RATIO : 1.33, # maximum aspect ratio of the crop
        MAX_ATTEMPTS : 100, # maximum number of attempts before returning the whole region
    },

    # Alternatively we can take a central crop from the image
    DO_CENTRAL_CROP : 0, # Fraction of the time to take a central crop, 0 is never, 1 is always
    CENTRAL_CROP_FRACTION : 0.875, # Between 0 and 1, fraction of size to crop

    # 3) We need to resize the extracted regions to feed into the network. 
    MAINTAIN_ASPECT_RATIO : false,
    # Avoid slower resize operations (bi-cubic, etc.)
    RESIZE_FAST : false,

    # 4) We can flip the regions
    # Randomly flip the image left right, 50% chance of flipping
    DO_RANDOM_FLIP_LEFT_RIGHT : true,

    # 5) We can distort the colors of the regions
    # The fraction of time to distort the color, 0 is never, 1 is always
    DO_COLOR_DISTORTION : 0.3, 
    # Avoids slower ops (random_hue and random_contrast)
    COLOR_DISTORT_FAST : false
}

# END: Image Processing and Augmentation
#################################################
# Queues
#
# Number of threads to populate the batch queue
NUM_INPUT_THREADS : 4
# Should the data be shuffled? 
SHUFFLE_QUEUE : true
# Capacity of the queue producing batched examples
QUEUE_CAPACITY : 1000
# Minimum size of the queue to ensure good shuffling
QUEUE_MIN :  200

# END: Queues
#################################################
# Saving Models and Summaries
#
# How often, in seconds, to save summaries.
SAVE_SUMMARY_SECS : 30

# How often, in seconds, to save the model
SAVE_INTERVAL_SECS : 1800

# The maximum number of recent checkpoint files to keep.
MAX_TO_KEEP : 3

# In addition to keeping the most recent `max_to_keep` checkpoint files, 
# you might want to keep one checkpoint file for every N hours of training
# The default value of 10,000 hours effectively disables the feature.
KEEP_CHECKPOINT_EVERY_N_HOURS : 10000

# The frequency, in terms of global steps, that the loss and global step and logged.
LOG_EVERY_N_STEPS : 10

# END: Saving Models and Summaries
#################################################
# Learning Rate Parameters
LEARNING_RATE_DECAY_TYPE : 'exponential' # One of "fixed", "exponential", or "polynomial"

INITIAL_LEARNING_RATE : 0.01

# The minimal end learning rate used by a polynomial decay learning rate.
END_LEARNING_RATE : 0.0001 

# The amount of label smoothing.
LABEL_SMOOTHING : 0.0

# How much to decay the learning rate
LEARNING_RATE_DECAY_FACTOR : 0.94
# Number of epochs between decaying the learning rate
NUM_EPOCHS_PER_DELAY : 4

LEARNING_RATE_STAIRCASE : true

# END: Learning Rate Parameters
#################################################
# Regularization 
#
# The decay to use for the moving average. If 0, then moving average is not computed
MOVING_AVERAGE_DECAY : 0.9999

# The weight decay on the model weights
WEIGHT_DECAY : 0.00004 

BATCHNORM_MOVING_AVERAGE_DECAY : 0.9997
BATCHNORM_EPSILON : 0.001

DROPOUT_KEEP_PROB : 0.8

CLIP_GRADIENT_NORM : 2 # If 0, no clipping is performed. Otherwise acts as a threshold to clip the gradients.

# End: Regularization
#################################################
# Optimization
#
# The name of the optimizer, one of "adadelta", "adagrad", "adam", "ftrl", "momentum", "sgd" or "rmsprop"
OPTIMIZER : 'rmsprop' 
OPTIMIZER_EPSILON : 1.0

# The decay rate for adadelta.
ADADELTA_RHO: 0.95

# Starting value for the AdaGrad accumulators.
ADAGRAD_INITIAL_ACCUMULATOR_VALUE: 0.1

# The exponential decay rate for the 1st moment estimates.
ADAM_BETA1 : 0.9
# The exponential decay rate for the 2nd moment estimates.
ADAM_BETA2 : 0.99

# The learning rate power.
FTRL_LEARNING_RATE_POWER : -0.5
# Starting value for the FTRL accumulators.
FTRL_INITIAL_ACCUMULATOR_VALUE : 0.1
# The FTRL l1 regularization strength.
FTRL_L1 : 0.0
# The FTRL l2 regularization strength.
FTRL_L2 : 0.0

# The momentum for the MomentumOptimizer and RMSPropOptimizer
MOMENTUM : 0.0

# Decay term for RMSProp.
RMSPROP_DECAY : 0.9 

# END: Optimization 
#################################################
